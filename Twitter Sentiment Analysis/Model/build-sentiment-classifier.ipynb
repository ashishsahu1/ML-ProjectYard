{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements an English-language tweet sentiment classifier based on the approach of [Go et al.](http://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf) The accuracy on the test data containing positive and negative sentiment tweets is 84%. Training and test data was downloaded [here](http://help.sentiment140.com/for-students/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-08-22T18:12:53.803508",
     "start_time": "2016-08-22T18:12:53.782794"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-08-22T17:59:18.946685",
     "start_time": "2016-08-22T17:59:14.935593"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['polarity', 'tweetid', 'date', 'query_name', 'user', 'text']\n",
    "dftrain = pd.read_csv('stanford-sentiment-twitter-data/training.1600000.processed.noemoticon.csv',\n",
    "                      header = None,\n",
    "                      encoding ='ISO-8859-1')\n",
    "dftest = pd.read_csv('stanford-sentiment-twitter-data/testdata.manual.2009.06.14.csv',\n",
    "                     header = None,\n",
    "                     encoding ='ISO-8859-1')\n",
    "dftrain.columns = columns\n",
    "dftest.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-08-22T17:59:18.972054",
     "start_time": "2016-08-22T17:59:18.947932"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RegexPreprocess(object):\n",
    "    \"\"\"Create a preprocessing module for a tweet or data structure of tweets.\n",
    "    1) replace username, e.g., @crawles -> USERNAME\n",
    "    2) replace http links -> URL\n",
    "    3) replace repeated letters to two letters\n",
    "    \"\"\"\n",
    "    \n",
    "    user_pat = '(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)'\n",
    "    http_pat = '(https?:\\/\\/(?:www\\.|(?!www))[^\\s\\.]+\\.[^\\s]{2,}|www\\.[^\\s]+\\.[^\\s]{2,})'\n",
    "    repeat_pat, repeat_repl = \"(.)\\\\1\\\\1+\",'\\\\1\\\\1'\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X):\n",
    "        is_pd_series = isinstance(X, pd.core.frame.Series)\n",
    "        if not is_pd_series:\n",
    "            pp_text = pd.Series(X)\n",
    "        else:\n",
    "            pp_text = X\n",
    "        pp_text = pp_text.str.replace(pat = self.user_pat, repl = 'USERNAME')\n",
    "        pp_text = pp_text.str.replace(pat = self.http_pat, repl = 'URL')\n",
    "        pp_text.str.replace(pat = self.repeat_pat, repl = self.repeat_repl)\n",
    "        return pp_text\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-08-22T18:00:08.871958",
     "start_time": "2016-08-22T17:59:18.973289"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('regex_preprocess', <__main__.RegexPreprocess object at 0x1354bc6a0>), ('count_vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_lr = Pipeline([('regex_preprocess', RegexPreprocess()),\n",
    "                         ('count_vect', CountVectorizer(min_df = 100,\n",
    "                                                        ngram_range = (1,1),\n",
    "                                                        stop_words = 'english')), \n",
    "                         ('lr', LogisticRegression())])\n",
    "sentiment_lr.fit(dftrain.text, dftrain.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-08-22T18:20:44.399305",
     "start_time": "2016-08-22T18:20:44.361151"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.81      0.83       177\n",
      "          4       0.82      0.87      0.85       182\n",
      "\n",
      "avg / total       0.84      0.84      0.84       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Xtest, ytest = dftest.text[dftest.polarity!=2], dftest.polarity[dftest.polarity!=2]\n",
    "print(classification_report(ytest,sentiment_lr.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export model for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-08-22T18:16:29.579602",
     "start_time": "2016-08-22T18:16:28.001270"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "f = open('twitter_sentiment_model.pkl','wb')\n",
    "r = RegexPreprocess()\n",
    "dill.dump(sentiment_lr, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-08-22T18:17:03.340734",
     "start_time": "2016-08-22T18:17:02.360369"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.81      0.83       177\n",
      "          4       0.82      0.87      0.85       182\n",
      "\n",
      "avg / total       0.84      0.84      0.84       359\n",
      "\n",
      "[[ 0.07068138  0.92931862]]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "f = open('twitter_sentiment_model.pkl','rb')\n",
    "cl = dill.load(f)\n",
    "print(classification_report(ytest,cl.predict(Xtest)))\n",
    "print(cl.predict_proba(\"Hello big beautiful world\"))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
