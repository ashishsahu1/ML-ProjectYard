{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insurance cost prediction using linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we're going to use information like a person's age, sex, BMI, no. of children and smoking habit to predict the price of yearly medical bills. This kind of model is useful for insurance companies to determine the yearly insurance premium for a person. The dataset for this problem is taken from Kaggle.<br>\n",
    "\n",
    "We will create a model with the following steps:<br>\n",
    "\n",
    "1. Download and explore the dataset\n",
    "2. Prepare the dataset for training\n",
    "3. Create a linear regression model\n",
    "4. Train the model to fit the data\n",
    "5. Make predictions using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import jovian\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Download and explore the data<br>\n",
    "Let us begin by downloading the data. We'll use the download_url function from PyTorch to get the data as a CSV (comma-separated values) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: .\\insurance.csv\n"
     ]
    }
   ],
   "source": [
    "DATASET_URL = \"https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv\"\n",
    "DATA_FILENAME = \"insurance.csv\"\n",
    "download_url(DATASET_URL, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the dataset into memory, we'll use the read_csv function from the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_raw = pd.read_csv(DATA_FILENAME)\n",
    "dataframe_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_name = \"gesha\" # at least 5 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The customize_dataset function will customize the dataset slightly using your name as a source of random numbers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_dataset(dataframe_raw, rand_str):\n",
    "    dataframe = dataframe_raw.copy(deep=True)\n",
    "    # drop some rows\n",
    "    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n",
    "    # scale input\n",
    "    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n",
    "    # scale target\n",
    "    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n",
    "    # drop column\n",
    "    if ord(rand_str[3]) % 2 == 1:\n",
    "        dataframe = dataframe.drop(['region'], axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>38</td>\n",
       "      <td>female</td>\n",
       "      <td>27.53765</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>7538.330902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>26</td>\n",
       "      <td>male</td>\n",
       "      <td>27.53765</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>5360.479303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>41</td>\n",
       "      <td>female</td>\n",
       "      <td>33.39060</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>8911.529860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>58</td>\n",
       "      <td>male</td>\n",
       "      <td>36.05700</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>13067.168250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>51</td>\n",
       "      <td>male</td>\n",
       "      <td>31.95135</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10550.255998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age     sex       bmi  children smoker     region       charges\n",
       "426   38  female  27.53765         1     no  northeast   7538.330902\n",
       "902   26    male  27.53765         3     no  northeast   5360.479303\n",
       "309   41  female  33.39060         2     no  northwest   8911.529860\n",
       "515   58    male  36.05700         0     no  southwest  13067.168250\n",
       "601   51    male  31.95135         0     no  northwest  10550.255998"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = customize_dataset(dataframe_raw, your_name)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1271\n"
     ]
    }
   ],
   "source": [
    "num_rows = dataframe.shape[0]\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "num_cols = dataframe.shape[1]\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'children', 'smoker', 'region']\n"
     ]
    }
   ],
   "source": [
    "#Column titles of input variables\n",
    "input_cols = dataframe.columns[:6]\n",
    "input_cols = input_cols.tolist()\n",
    "print(input_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'smoker', 'region']\n"
     ]
    }
   ],
   "source": [
    "#categorical variables\n",
    "\n",
    "categorical_cols = dataframe.select_dtypes(exclude=[\"number\"]) # [\"sex\", \"smoker\"]\n",
    "categorical_cols = categorical_cols.columns\n",
    "categorical_cols = categorical_cols.tolist()\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['charges']\n"
     ]
    }
   ],
   "source": [
    "#target variable\n",
    "output_cols = dataframe.columns[6:].tolist()\n",
    "print(output_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Prepare the dataset for training\n",
    "We need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out input_cols, categorial_cols and output_cols correctly, this following function will perform the conversion to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_arrays(dataframe):\n",
    "    # Make a copy of the original dataframe\n",
    "    dataframe1 = dataframe.copy(deep=True)\n",
    "    # Convert non-numeric categorical columns to numbers\n",
    "    for col in categorical_cols:\n",
    "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
    "    # Extract input & outupts as numpy arrays\n",
    "    inputs_array = dataframe1[input_cols].to_numpy()\n",
    "    targets_array = dataframe1[output_cols].to_numpy()\n",
    "    return inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[38.     ,  0.     , 27.53765,  1.     ,  0.     ,  0.     ],\n",
       "        [26.     ,  1.     , 27.53765,  3.     ,  0.     ,  0.     ],\n",
       "        [41.     ,  0.     , 33.3906 ,  2.     ,  0.     ,  1.     ],\n",
       "        ...,\n",
       "        [24.     ,  1.     , 33.027  ,  0.     ,  1.     ,  3.     ],\n",
       "        [31.     ,  1.     , 26.159  ,  3.     ,  1.     ,  3.     ],\n",
       "        [43.     ,  1.     , 30.401  ,  1.     ,  0.     ,  3.     ]]),\n",
       " array([[ 7538.3309025],\n",
       "        [ 5360.4793025],\n",
       "        [ 8911.52986  ],\n",
       "        ...,\n",
       "        [39643.76715  ],\n",
       "        [22079.9356   ],\n",
       "        [ 7876.3799   ]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
    "inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(np.float32(inputs_array))\n",
    "targets = torch.from_numpy(np.float32(targets_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype, targets.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(inputs, targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a number between 0.1 and 0.2 to determine the fraction of data that will be used for creating the validation set. Then use random_split to create training & validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_percent = 0.15 # between 0.1 and 0.2\n",
    "val_size = int(num_rows * val_percent)\n",
    "train_size = num_rows - val_size\n",
    "\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size]) # Use the random_split function to split dataset into 2 parts of the desired length\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create data loaders for training & validation.<br>\n",
    "Pick a batch size for the data loader.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[41.0000,  1.0000, 28.6891,  1.0000,  0.0000,  1.0000],\n",
      "        [19.0000,  0.0000, 40.0112,  1.0000,  0.0000,  1.0000],\n",
      "        [53.0000,  1.0000, 21.6140,  1.0000,  0.0000,  3.0000],\n",
      "        [31.0000,  0.0000, 21.9725,  0.0000,  0.0000,  1.0000],\n",
      "        [56.0000,  0.0000, 42.3291,  0.0000,  0.0000,  2.0000],\n",
      "        [54.0000,  0.0000, 32.2190,  1.0000,  0.0000,  2.0000],\n",
      "        [49.0000,  0.0000, 30.2243,  0.0000,  0.0000,  1.0000],\n",
      "        [21.0000,  0.0000, 16.9832,  1.0000,  0.0000,  0.0000],\n",
      "        [27.0000,  1.0000, 28.7850,  0.0000,  1.0000,  1.0000],\n",
      "        [30.0000,  1.0000, 31.8857,  3.0000,  0.0000,  2.0000],\n",
      "        [18.0000,  1.0000, 16.1196,  0.0000,  0.0000,  0.0000],\n",
      "        [34.0000,  1.0000, 21.5888,  0.0000,  0.0000,  0.0000],\n",
      "        [53.0000,  1.0000, 28.8860,  3.0000,  0.0000,  3.0000],\n",
      "        [63.0000,  1.0000, 35.4409,  0.0000,  1.0000,  2.0000],\n",
      "        [49.0000,  1.0000, 31.6635,  1.0000,  0.0000,  0.0000],\n",
      "        [50.0000,  0.0000, 46.5509,  1.0000,  0.0000,  2.0000]])\n",
      "targets: tensor([[ 7664.3887],\n",
      "        [ 3139.6240],\n",
      "        [11575.2246],\n",
      "        [ 4754.1948],\n",
      "        [12757.6660],\n",
      "        [12568.1768],\n",
      "        [10336.3828],\n",
      "        [ 3642.5742],\n",
      "        [21057.3535],\n",
      "        [ 5563.2197],\n",
      "        [ 1949.0159],\n",
      "        [ 5175.3901],\n",
      "        [12941.4346],\n",
      "        [54113.8633],\n",
      "        [10683.6602],\n",
      "        [10982.0000]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_loader:\n",
    "    print(\"inputs:\", xb)\n",
    "    print(\"targets:\", yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create a Linear Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(input_cols)\n",
    "output_size = len(output_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsuranceModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size) # fill this (hint: use input_size & output_size defined above)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        # xb = xb.reshape(-1, input_size * input_size) # check if we need to reshape\n",
    "        out = self.linear(xb)                          # fill this\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch \n",
    "        # Generate predictions\n",
    "        out = self(inputs)          \n",
    "        # Calcuate loss\n",
    "        loss = F.l1_loss(out, targets)                          # fill this\n",
    "        # l1_loss: Function that takes the mean element-wise absolute value difference.\n",
    "        # smooth_l1_loss: \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        # Generate predictions\n",
    "        out = self(inputs)\n",
    "        # Calculate loss\n",
    "        loss = F.l1_loss(out, targets)                           # fill this\n",
    "        return {'val_loss': loss.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        # Print result every 20th epoch\n",
    "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
    "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a model using the InsuranceModel class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes nan or infinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InsuranceModel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the weights and biases of the model using model.parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.3066,  0.1402, -0.2322,  0.0151,  0.3637, -0.3625]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2143], requires_grad=True)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the model to fit the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 16748.201171875}\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(model, val_loader) # Use the the evaluate function\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or nan), you may have to re-initialize the model by running the cell model = InsuranceModel()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 9755.7412\n",
      "Epoch [40], val_loss: 9597.8115\n",
      "Epoch [60], val_loss: 9460.9121\n",
      "Epoch [80], val_loss: 9344.7764\n",
      "Epoch [100], val_loss: 9266.5410\n",
      "Epoch [120], val_loss: 9217.2070\n",
      "Epoch [140], val_loss: 9196.8838\n",
      "Epoch [160], val_loss: 9185.2256\n",
      "Epoch [180], val_loss: 9181.5410\n",
      "Epoch [200], val_loss: 9179.9482\n",
      "Epoch [220], val_loss: 9177.1729\n",
      "Epoch [240], val_loss: 9175.5215\n",
      "Epoch [260], val_loss: 9173.5146\n",
      "Epoch [280], val_loss: 9171.5752\n",
      "Epoch [300], val_loss: 9169.6445\n",
      "Epoch [320], val_loss: 9168.3857\n",
      "Epoch [340], val_loss: 9166.3740\n",
      "Epoch [360], val_loss: 9163.8877\n",
      "Epoch [380], val_loss: 9162.2959\n",
      "Epoch [400], val_loss: 9160.9033\n",
      "Epoch [420], val_loss: 9158.1865\n",
      "Epoch [440], val_loss: 9156.0615\n",
      "Epoch [460], val_loss: 9153.7256\n",
      "Epoch [480], val_loss: 9152.3936\n",
      "Epoch [500], val_loss: 9151.4014\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "lr = 1e-2\n",
    "history1 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 9150.9736\n",
      "Epoch [40], val_loss: 9150.7061\n",
      "Epoch [60], val_loss: 9150.5098\n",
      "Epoch [80], val_loss: 9150.2764\n",
      "Epoch [100], val_loss: 9150.1699\n",
      "Epoch [120], val_loss: 9149.9961\n",
      "Epoch [140], val_loss: 9149.8076\n",
      "Epoch [160], val_loss: 9149.6670\n",
      "Epoch [180], val_loss: 9149.3682\n",
      "Epoch [200], val_loss: 9149.0498\n",
      "Epoch [220], val_loss: 9148.9482\n",
      "Epoch [240], val_loss: 9148.7295\n",
      "Epoch [260], val_loss: 9148.7393\n",
      "Epoch [280], val_loss: 9148.6357\n",
      "Epoch [300], val_loss: 9148.4619\n",
      "Epoch [320], val_loss: 9148.2559\n",
      "Epoch [340], val_loss: 9148.0537\n",
      "Epoch [360], val_loss: 9147.8838\n",
      "Epoch [380], val_loss: 9147.5654\n",
      "Epoch [400], val_loss: 9147.3701\n",
      "Epoch [420], val_loss: 9147.3008\n",
      "Epoch [440], val_loss: 9147.0400\n",
      "Epoch [460], val_loss: 9146.7930\n",
      "Epoch [480], val_loss: 9146.6221\n",
      "Epoch [500], val_loss: 9146.5508\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "lr = 1e-3\n",
    "history2 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 9146.5361\n",
      "Epoch [40], val_loss: 9146.5225\n",
      "Epoch [60], val_loss: 9146.5244\n",
      "Epoch [80], val_loss: 9146.5068\n",
      "Epoch [100], val_loss: 9146.4883\n",
      "Epoch [120], val_loss: 9146.4619\n",
      "Epoch [140], val_loss: 9146.4443\n",
      "Epoch [160], val_loss: 9146.4463\n",
      "Epoch [180], val_loss: 9146.4199\n",
      "Epoch [200], val_loss: 9146.3975\n",
      "Epoch [220], val_loss: 9146.3779\n",
      "Epoch [240], val_loss: 9146.3682\n",
      "Epoch [260], val_loss: 9146.3525\n",
      "Epoch [280], val_loss: 9146.3477\n",
      "Epoch [300], val_loss: 9146.3408\n",
      "Epoch [320], val_loss: 9146.3271\n",
      "Epoch [340], val_loss: 9146.3174\n",
      "Epoch [360], val_loss: 9146.3096\n",
      "Epoch [380], val_loss: 9146.3047\n",
      "Epoch [400], val_loss: 9146.2852\n",
      "Epoch [420], val_loss: 9146.2666\n",
      "Epoch [440], val_loss: 9146.2588\n",
      "Epoch [460], val_loss: 9146.2393\n",
      "Epoch [480], val_loss: 9146.2295\n",
      "Epoch [500], val_loss: 9146.2217\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "lr = 1e-4\n",
    "history3 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 9146.2217\n",
      "Epoch [40], val_loss: 9146.2217\n",
      "Epoch [60], val_loss: 9146.2197\n",
      "Epoch [80], val_loss: 9146.2197\n",
      "Epoch [100], val_loss: 9146.2197\n",
      "Epoch [120], val_loss: 9146.2178\n",
      "Epoch [140], val_loss: 9146.2197\n",
      "Epoch [160], val_loss: 9146.2188\n",
      "Epoch [180], val_loss: 9146.2139\n",
      "Epoch [200], val_loss: 9146.2139\n",
      "Epoch [220], val_loss: 9146.2148\n",
      "Epoch [240], val_loss: 9146.2158\n",
      "Epoch [260], val_loss: 9146.2158\n",
      "Epoch [280], val_loss: 9146.2158\n",
      "Epoch [300], val_loss: 9146.2139\n",
      "Epoch [320], val_loss: 9146.2139\n",
      "Epoch [340], val_loss: 9146.2129\n",
      "Epoch [360], val_loss: 9146.2139\n",
      "Epoch [380], val_loss: 9146.2139\n",
      "Epoch [400], val_loss: 9146.2129\n",
      "Epoch [420], val_loss: 9146.2139\n",
      "Epoch [440], val_loss: 9146.2119\n",
      "Epoch [460], val_loss: 9146.2139\n",
      "Epoch [480], val_loss: 9146.2129\n",
      "Epoch [500], val_loss: 9146.2119\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "lr = 1e-5\n",
    "history4 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 9146.2119\n",
      "Epoch [40], val_loss: 9146.2109\n",
      "Epoch [60], val_loss: 9146.2119\n",
      "Epoch [80], val_loss: 9146.2109\n",
      "Epoch [100], val_loss: 9146.2109\n",
      "Epoch [120], val_loss: 9146.2119\n",
      "Epoch [140], val_loss: 9146.2139\n",
      "Epoch [160], val_loss: 9146.2139\n",
      "Epoch [180], val_loss: 9146.2148\n",
      "Epoch [200], val_loss: 9146.2148\n",
      "Epoch [220], val_loss: 9146.2129\n",
      "Epoch [240], val_loss: 9146.2119\n",
      "Epoch [260], val_loss: 9146.2129\n",
      "Epoch [280], val_loss: 9146.2139\n",
      "Epoch [300], val_loss: 9146.2139\n",
      "Epoch [320], val_loss: 9146.2139\n",
      "Epoch [340], val_loss: 9146.2139\n",
      "Epoch [360], val_loss: 9146.2119\n",
      "Epoch [380], val_loss: 9146.2119\n",
      "Epoch [400], val_loss: 9146.2119\n",
      "Epoch [420], val_loss: 9146.2100\n",
      "Epoch [440], val_loss: 9146.2100\n",
      "Epoch [460], val_loss: 9146.2119\n",
      "Epoch [480], val_loss: 9146.2100\n",
      "Epoch [500], val_loss: 9146.2100\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "lr = 1e-6\n",
    "history5 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final validation loss of your model\n",
    "val_loss = 7810.9771"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Make predictions using the trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(input, target, model):\n",
    "    inputs = input.unsqueeze(0)\n",
    "    predictions = model(inputs)               \n",
    "    prediction = predictions[0].detach()\n",
    "    print(\"Input:\", input)\n",
    "    print(\"Target:\", target)\n",
    "    print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([19.0000,  0.0000, 28.1790,  0.0000,  1.0000,  3.0000])\n",
      "Target: tensor([19417.6621])\n",
      "Prediction: tensor([2874.9050])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[0]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([56.0000,  0.0000, 28.5931,  0.0000,  0.0000,  0.0000])\n",
      "Target: tensor([13406.3770])\n",
      "Prediction: tensor([13721.3887])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[10]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([47.0000,  0.0000, 23.8360,  1.0000,  0.0000,  3.0000])\n",
      "Target: tensor([9820.6221])\n",
      "Prediction: tensor([11435.4199])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[23]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'linear_regression.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
